import pandas as pd
import numpy as np
import joblib
import shap
import matplotlib.pyplot as plt
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error
from keras.models import Sequential
from keras.layers import GRU, Dense, Dropout, Input, Conv1D, Flatten, MaxPooling1D, LSTM
from joblib import Parallel, delayed
import keras.backend as K

# ==========================================
# 1. –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø
# ==========================================
# –í—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ
dynamic_cols = [
    'steps', 'very_active_minutes', 'minutesAsleep', 'sleep_efficiency', 
    'nremhr', 'stress_score', 'nightly_temperature', 'resting_hr',
    # –ù–û–í–Ü "–î–û–í–ì–Ü" –§–Ü–ß–Ü:
    'chronic_steps', 'acute_steps', 'acwr' 
]
# –°—Ç–∞—Ç–∏—á–Ω—ñ –æ–∑–Ω–∞–∫–∏ (–Ω–µ –∑–º—ñ–Ω—é—é—Ç—å—Å—è –∑ —á–∞—Å–æ–º)
static_cols = ['age', 'bmi']
# –Ü–Ω—Ñ–æ—Ä–º–∞—Ü—ñ—è –ø—Ä–æ –≤–∏—Ö—ñ–¥–Ω—ñ –¥–Ω—ñ
weekend_col = ['is_weekend']

# –¶—ñ–ª—å–æ–≤–∞ –∫–æ–ª–æ–Ω–∫–∞ - Delta (–∑–º—ñ–Ω–∞ –ø—É–ª—å—Å—É)
target_col = 'hr_delta' 

# –†–æ–∑–º—ñ—Ä —á–∞—Å–æ–≤–æ–≥–æ –≤—ñ–∫–Ω–∞ –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É (–∫—ñ–ª—å–∫—ñ—Å—Ç—å –¥–Ω—ñ–≤ –≤ —ñ—Å—Ç–æ—Ä—ñ—ó)
DAYS_WINDOW = 3  # –ú–æ–¥–µ–ª—å –¥–∏–≤–∏—Ç—å—Å—è –Ω–∞ 3 –¥–Ω—ñ–≤ –Ω–∞–∑–∞–¥ –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ü—ñ—ó

# ==========================================
# 2. –§–£–ù–ö–¶–Ü–á
# ==========================================

def create_dataset(dataset, target_index, time_steps=DAYS_WINDOW):
    """
    –°—Ç–≤–æ—Ä—é—î —Å–ª–∞–π–¥—É—é—á—ñ –≤—ñ–∫–Ω–∞ —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤.
    
    Args:
        dataset: –ú–∞—Å–∏–≤ –¥–∞–Ω–∏—Ö (n_samples, n_features)
        target_index: –Ü–Ω–¥–µ–∫—Å —Ü—ñ–ª—å–æ–≤–æ—ó –∑–º—ñ–Ω–Ω–æ—ó
        time_steps: –†–æ–∑–º—ñ—Ä –≤—ñ–∫–Ω–∞ (DAYS_WINDOW –¥–Ω—ñ–≤)
    
    Returns:
        X: –ú–∞—Å–∏–≤ —Ñ–æ—Ä–º–∏ (n_samples, time_steps, n_features) - –≤—Ö–æ–¥–∏ –¥–ª—è –º–æ–¥–µ–ª—ñ
        Y: –ú–∞—Å–∏–≤ —Ü—ñ–ª—å–æ–≤–∏—Ö –∑–Ω–∞—á–µ–Ω—å –¥–ª—è –∫–æ–∂–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞
    """
    X, Y = [], []
    for i in range(len(dataset) - time_steps):
        X.append(dataset[i:(i + time_steps), :])
        Y.append(dataset[i + time_steps, target_index])
    return np.array(X), np.array(Y)

def build_model(input_shape, model_type='GRU'):
    """
    –ë—É–¥—É—î –Ω–µ–π—Ä–æ–Ω–Ω—É –º–µ—Ä–µ–∂—É –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ü—ñ—ó.
    
    Args:
        input_shape: –ö–æ—Ä—Ç–µ–∂ (DAYS_WINDOW, n_features) - —Ñ–æ—Ä–º–∞ –≤—Ö–æ–¥—É
        model_type: –¢–∏–ø –∞—Ä—Ö—ñ—Ç–µ–∫—Ç—É—Ä–∏ ('GRU', 'LSTM' –∞–±–æ 'CNN')
    
    Returns:
        model: –°–∫–æ–º–ø—ñ–ª—å–æ–≤–∞–Ω–∞ Keras –º–æ–¥–µ–ª—å
    
    –ü—Ä–∏–º—ñ—Ç–∫–∞:
        - GRU/LSTM —Ö–æ—Ä–æ—à—ñ –¥–ª—è –ø–æ—Å–ª—ñ–¥–æ–≤–Ω–æ—Å—Ç–µ–π
        - CNN –∫—Ä–∞—â–∞ –¥–ª—è –ª–æ–∫–∞–ª—å–Ω–∏—Ö –ø–∞—Ç–µ—Ä–Ω—ñ–≤
    """
    model = Sequential()
    model.add(Input(shape=input_shape))
    
    if model_type == 'GRU':
        # GRU —à–∞—Ä–∏ –¥–ª—è –æ–±—Ä–æ–±–∫–∏ —á–∞—Å–æ–≤–∏—Ö —Ä—è–¥—ñ–≤
        model.add(GRU(64, return_sequences=True))  # –ü–æ–≤–µ—Ä—Ç–∞—î –≤—Å—é –ø–æ—Å–ª—ñ–¥–æ–≤–Ω—ñ—Å—Ç—å
        model.add(Dropout(0.3))  # –†–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü—ñ—è (–≤–∏–º–∏–∫–∞—î 30% –Ω–µ–π—Ä–æ–Ω—ñ–≤)
        model.add(GRU(64))  # –§—ñ–Ω–∞–ª—å–Ω–∏–π —à–∞—Ä –ø–æ–≤–µ—Ä—Ç–∞—î —Ç—ñ–ª—å–∫–∏ –æ—Å—Ç–∞–Ω–Ω—ñ–π –≤–∏—Ö—ñ–¥
        
    elif model_type == 'LSTM':
        # LSTM - –∞–ª—å—Ç–µ—Ä–Ω–∞—Ç–∏–≤–∞ GRU –∑ –±—ñ–ª—å—à–æ—é –ø–∞–º'—è—Ç—Ç—é
        model.add(LSTM(64, return_sequences=True))
        model.add(Dropout(0.3))
        model.add(LSTM(64))
        
    elif model_type == 'CNN':
        # –ó–≥–æ—Ä—Ç–∫–æ–≤—ñ —à–∞—Ä–∏ –¥–ª—è –ø–æ—à—É–∫—É –ª–æ–∫–∞–ª—å–Ω–∏—Ö –ø–∞—Ç–µ—Ä–Ω—ñ–≤
        model.add(Conv1D(filters=64, kernel_size=2, activation='relu'))
        model.add(MaxPooling1D(pool_size=1))
        model.add(Flatten())  # –†–æ–∑–≥–æ—Ä—Ç–∞–Ω–Ω—è –≤ 1D –≤–µ–∫—Ç–æ—Ä
        model.add(Dense(50, activation='relu'))

    # –§—ñ–Ω–∞–ª—å–Ω—ñ —à–∞—Ä–∏ –¥–ª—è –ø–µ—Ä–µ–¥–∏–∫—Ü—ñ—ó –æ–¥–Ω—ñ—î—ó —Ü—ñ–Ω–Ω–æ—Å—Ç—ñ (–∑–º—ñ–Ω–∞ –ø—É–ª—å—Å—É)
    model.add(Dropout(0.3))
    model.add(Dense(32, activation='relu'))
    model.add(Dense(1))  # –í–∏—Ö—ñ–¥ - –æ–¥–Ω–µ —á–∏—Å–ª–æ (–∑–º—ñ–Ω–∞ –≤ BPM)
    model.compile(optimizer='adam', loss='mse')  # MSE –¥–ª—è —Ä–µ–≥—Ä–µ—Å—ñ—ó
    return model

def process_user_with_delta(df, user_id, dynamic_cols, static_cols, scaler_X=None, scaler_Y=None):
    """
    –ü—Ä–µ–ø—Ä–æ—Ü–µ—Å—É—î –¥–∞–Ω—ñ –æ–¥–Ω–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞.
    
    Args:
        df: DataFrame –∑ —É—Å—ñ–º–∞ –¥–∞–Ω–∏–º–∏
        user_id: ID –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        dynamic_cols: –°–ø–∏—Å–æ–∫ –¥–∏–Ω–∞–º—ñ—á–Ω–∏—Ö –æ–∑–Ω–∞–∫
        static_cols: –°–ø–∏—Å–æ–∫ —Å—Ç–∞—Ç–∏—á–Ω–∏—Ö –æ–∑–Ω–∞–∫
        scaler_X: –ü–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–∏–π scaler –¥–ª—è X (—è–∫—â–æ None - –Ω–∞–≤—á–∞—î—Ç—å—Å—è –Ω–∞ —Ü—å–æ–º—É –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–µ–≤—ñ)
        scaler_Y: –ü–æ–ø–µ—Ä–µ–¥–Ω—å–æ –Ω–∞–≤—á–µ–Ω–∏–π scaler –¥–ª—è Y (—Ü—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞)
    
    Returns:
        X_final: –ú–∞—Å–∏–≤ –æ–∑–Ω–∞–∫ (n_days, n_features)
        y_scaled: –ú–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω–∞ —Ü—ñ–ª—å–æ–≤–∞ –∑–º—ñ–Ω–Ω–∞ (–∑–º—ñ–Ω–∞ –ø—É–ª—å—Å—É)
        scaler_X: –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏–π scaler –¥–ª—è X
        scaler_Y: –í–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–∏–π scaler –¥–ª—è Y
        raw_bpm: –ü–æ—á–∞—Ç–∫–æ–≤—ñ –∑–Ω–∞—á–µ–Ω–Ω—è –ø—É–ª—å—Å—É (–¥–ª—è —Ä–æ–∑—Ä–∞—Ö—É–Ω–∫—É –∞–±—Å–æ–ª—é—Ç–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å)
    """
    # –í–∏–±–∏—Ä–∞—î–º–æ –¥–∞–Ω—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ —Ç–∞ –∑–∞–ø–æ–≤–Ω—é—î–º–æ –ø—Ä–æ–ø—É—Å–∫–∏
    user_df = df[df['id'] == user_id].copy()
    
    # 1. –û–ë–ß–ò–°–õ–Æ–Ñ–ú–û "–î–û–í–ì–Ü" –ú–ï–¢–†–ò–ö–ò (–¥–æ –≤–∏–¥–∞–ª–µ–Ω–Ω—è NaN)
    # Chronic Load (–•—Ä–æ–Ω—ñ—á–Ω–µ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è) - —Å–µ—Ä–µ–¥–Ω—î –∑–∞ 28 –¥–Ω—ñ–≤ (4 —Ç–∏–∂–Ω—ñ)
    # min_periods=1 –¥–æ–∑–≤–æ–ª—è—î —Ä–∞—Ö—É–≤–∞—Ç–∏ –Ω–∞–≤—ñ—Ç—å –Ω–∞ –ø–æ—á–∞—Ç–∫—É, –ø–æ–∫–∏ –Ω–µ–º–∞—î 28 –¥–Ω—ñ–≤
    user_df['chronic_steps'] = user_df['steps'].rolling(window=28, min_periods=1).mean()
    
    # Acute Load (–ì–æ—Å—Ç—Ä–µ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è) - —Å–µ—Ä–µ–¥–Ω—î –∑–∞ 7 –¥–Ω—ñ–≤
    user_df['acute_steps'] = user_df['steps'].rolling(window=7, min_periods=1).mean()
    
    # ACWR (Acute:Chronic Workload Ratio)
    # –î–æ–¥–∞—î–º–æ +1 —É –∑–Ω–∞–º–µ–Ω–Ω–∏–∫, —â–æ–± —É–Ω–∏–∫–Ω—É—Ç–∏ –¥—ñ–ª–µ–Ω–Ω—è –Ω–∞ 0, —è–∫—â–æ —é–∑–µ—Ä –Ω–µ —Ö–æ–¥–∏–≤ –º—ñ—Å—è—Ü—å
    user_df['acwr'] = user_df['acute_steps'] / (user_df['chronic_steps'] + 1)
    
    # 2. –°–¢–í–û–†–Æ–Ñ–ú–û DELTA (–ó–ú–Ü–ù–£)
    user_df['hr_delta'] = user_df['resting_hr'].diff().fillna(0)
    
    # –ó–∞–ø–æ–≤–Ω—é—î–º–æ –ø—Ä–æ–ø—É—Å–∫–∏, —è–∫—ñ –º–æ–≥–ª–∏ –≤–∏–Ω–∏–∫–Ω—É—Ç–∏ (ffill/bfill)
    user_df = user_df.ffill().bfill()
    
    # –í–∏–¥–∞–ª—è—î–º–æ –ø–µ—Ä—à–∏–π —Ä—è–¥–æ–∫ (–±–æ —Ç–∞–º delta –Ω–µ–∫–æ—Ä–µ–∫—Ç–Ω–∞)
    user_df = user_df.iloc[1:].reset_index(drop=True)

    # 3. –û–±—Ä–æ–±–∫–∞ X (–í—Ö—ñ–¥–Ω—ñ –¥–∞–Ω—ñ)
    # –¢–µ–ø–µ—Ä input_features –≤–∫–ª—é—á–∞—î —ñ –Ω–æ–≤—ñ –∫–æ–ª–æ–Ω–∫–∏ (acwr, chronic...), –±–æ –º–∏ –¥–æ–¥–∞–ª–∏ —ó—Ö —É dynamic_cols
    input_features = user_df[dynamic_cols].values
    
    # –°–∫–µ–π–ª–∏–Ω–≥ –î–∏–Ω–∞–º—ñ–∫–∏ (–≤—Å—ñ—Ö 11 –∫–æ–ª–æ–Ω–æ–∫)
    if scaler_X is None:
        scaler_X = StandardScaler()
        dyn_scaled = scaler_X.fit_transform(input_features)
    else:
        dyn_scaled = scaler_X.transform(input_features)
        
    # –°–∫–µ–π–ª–∏–Ω–≥ –°—Ç–∞—Ç–∏–∫–∏ + Weekend
    try:
        stat_data = user_df[static_cols].values
        stat_data[:, 0] = stat_data[:, 0] / 100.0 # Age
        stat_data[:, 1] = stat_data[:, 1] / 50.0  # BMI
        week_data = user_df[weekend_col].values
    except KeyError:
        stat_data = np.zeros((len(user_df), 2))
        week_data = np.zeros((len(user_df), 1))
        
    X_final = np.hstack((dyn_scaled, stat_data, week_data))
    
    # 4. –û–±—Ä–æ–±–∫–∞ Y (–¢—ñ–ª—å–∫–∏ Delta)
    target_values = user_df[[target_col]].values
    if scaler_Y is None:
        scaler_Y = StandardScaler()
        y_scaled = scaler_Y.fit_transform(target_values)
    else:
        y_scaled = scaler_Y.transform(target_values)
        
    raw_bpm = user_df['resting_hr'].values
        
    return X_final, y_scaled, scaler_X, scaler_Y, raw_bpm

# ==========================================
# 3. –û–°–ù–û–í–ù–ò–ô –¶–ò–ö–õ (5-Fold Cross-Validation)
# ==========================================
# 5-Fold CV —Ä–æ–∑–¥—ñ–ª—è—î –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –Ω–∞ 5 –≥—Ä—É–ø –¥–ª—è–µ—Ñ–µ–∫—Ç–∏–≤–Ω–æ—ó –æ—Ü—ñ–Ω–∫–∏
if __name__ == "__main__":
    # –ó–∞–≤–∞–Ω—Ç–∞–∂—É—î–º–æ —Ç–∞ –ø—Ä–µ–ø—Ä–æ—Ü–µ—Å—É—î–º–æ –¥–∞–Ω—ñ
    df = pd.read_csv('cursova/daily_fitbit_sema_df_processed.csv') 
    df['age'] = pd.to_numeric(df['age'], errors='coerce').fillna(30)  # –ó–∞–ø–æ–≤–Ω—é—î–º–æ –ø—Ä–æ–ø—É—Å–∫–∏
    df['bmi'] = pd.to_numeric(df['bmi'], errors='coerce').fillna(25)
    df['date'] = pd.to_datetime(df['date'])
    # –í–∏–∑–Ω–∞—á–∞—î–º–æ –≤–∏—Ö—ñ–¥–Ω—ñ –¥–Ω—ñ (—Å—É–±–æ—Ç–∞=5, –Ω–µ–¥—ñ–ª—è=6)
    df['is_weekend'] = (df['date'].dt.dayofweek >= 5).astype(int)

    # –†–æ–∑–¥—ñ–ª—è—î–º–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –¥–ª—è 5-Fold CV
    all_users = df['id'].unique().tolist()
    user_folds = np.array_split(all_users, 5)  # 5 –≥—Ä—É–ø–ø –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
    
    print(f"üöÄ –ó–∞–ø—É—Å–∫ Delta-Prediction (Window={DAYS_WINDOW} days)...")

    def evaluate_delta_fold(fold_idx, folds):
        """
        –û—Ü—ñ–Ω—é—î –º–æ–¥–µ–ª—å –Ω–∞ –æ–¥–Ω–æ–º—É —Ñ–æ–ª–¥—ñ CV.
        
        Args:
            fold_idx: –Ü–Ω–¥–µ–∫—Å —Ç–µ—Å—Ç–æ–≤–æ–≥–æ —Ñ–æ–ª–¥—É (0-4)
            folds: –°–ø–∏—Å–æ–∫ –≤—Å—ñ—Ö —Ñ–æ–ª–¥—ñ–≤ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
        
        Returns:
            –ö–æ—Ä—Ç–µ–∂ (MAE, MSE, R2) - –º–µ—Ç—Ä–∏–∫–∏ –Ω–∞ —Ç–µ—Å—Ç–æ–≤–æ–º—É –Ω–∞–±–æ—Ä—ñ
        """
        # –†–æ–∑–¥—ñ–ª 1: –ü—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ—ó —Ç–∞ —Ç–µ—Å—Ç–æ–≤–æ—ó –≥—Ä—É–ø–∏
        test_group = folds[fold_idx]  # 20% –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
        train_group = np.concatenate([folds[i] for i in range(5) if i != fold_idx])  # 80% –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è
        
        # --- –ü–Ü–î–ì–û–¢–û–í–ö–ê TRAIN –î–ê–ù–ò–• ---
        X_train_list, y_train_list = [], []
        
        for u in train_group:
            # –û–±—Ä–æ–±–ª—è—î–º–æ –∫–æ–∂–Ω–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞ –∑ —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–æ—ó –≥—Ä—É–ø–∏
            X_u, y_u_scaled, _, _, _ = process_user_with_delta(df, u, dynamic_cols, static_cols)
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Å–ª–∞–π–¥—É—é—á—ñ –≤—ñ–∫–Ω–∞ —Ä–æ–∑–º—ñ—Ä–æ–º DAYS_WINDOW
            # –î–ª—è –∫–æ–∂–Ω–æ–≥–æ –≤—ñ–∫–Ω–∞: X = 14 –¥–Ω—ñ–≤ —ñ—Å—Ç–æ—Ä—ñ—ó, Y = –∑–º—ñ–Ω–∞ –ø—É–ª—å—Å—É –Ω–∞ –¥–µ–Ω—å 15
            X_wins, y_wins = [], []
            for i in range(len(X_u) - DAYS_WINDOW):
                X_wins.append(X_u[i : i + DAYS_WINDOW])  # 14 –¥–Ω—ñ–≤ (4D –≤–µ–∫—Ç–æ—Ä)
                y_wins.append(y_u_scaled[i + DAYS_WINDOW])  # –¶—ñ–Ω–Ω—ñ—Å—Ç—å –Ω–∞ –¥–µ–Ω—å 15
            
            if len(X_wins) > 0:
                X_train_list.append(np.array(X_wins))
                y_train_list.append(np.array(y_wins))
        
        # –û–±'—î–¥–Ω—É—î–º–æ –≤—Å—ñ –≤—ñ–∫–Ω–∞ –≤—ñ–¥ —É—Å—ñ—Ö –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á—ñ–≤
        X_train = np.concatenate(X_train_list, axis=0)  # –§–æ—Ä–º–∞: (n_windows, 14, n_features)
        y_train = np.concatenate(y_train_list, axis=0)  # –§–æ—Ä–º–∞: (n_windows,)
        
        # --- –ù–ê–í–ß–ê–ù–ù–Ø –ú–û–î–ï–õ–Ü ---
        model = build_model((X_train.shape[1], X_train.shape[2]), model_type='GRU')
        model.fit(X_train, y_train, epochs=20, batch_size=32, verbose=0)
        
        # --- –¢–ï–°–¢–£–í–ê–ù–ù–Ø –ù–ê –ö–û–ñ–ù–û–ú–£ –ö–û–†–ò–°–¢–£–í–ê–ß–Ü ---
        mae_list, mse_list, r2_list = [], [], []
        
        for test_user in test_group:
            # –û–±—Ä–æ–±–ª—è—î–º–æ —Ç–µ—Å—Ç–æ–≤–æ–≥–æ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
            X_u, y_u_scaled, sc_X, sc_Y, raw_bpm = process_user_with_delta(df, test_user, dynamic_cols, static_cols)
            
            X_test, y_test_scaled = [], []
            actual_prev_bpm = []   # –ü—É–ª—å—Å –≤ –æ—Å—Ç–∞–Ω–Ω—ñ–π –¥–µ–Ω—å –≤—ñ–∫–Ω–∞
            actual_future_bpm = []  # –†–µ–∞–ª—å–Ω–∏–π –ø—É–ª—å—Å –Ω–∞—Å—Ç—É–ø–Ω–æ–≥–æ –¥–Ω—è
            
            # –°—Ç–≤–æ—Ä—é—î–º–æ —Ç–µ—Å—Ç–æ–≤—ñ –≤—ñ–∫–Ω–∞
            for i in range(len(X_u) - DAYS_WINDOW):
                X_test.append(X_u[i : i + DAYS_WINDOW])
                y_test_scaled.append(y_u_scaled[i + DAYS_WINDOW])
                
                # raw_bpm[i + DAYS_WINDOW - 1] = –ø—É–ª—å—Å –Ω–∞ –¥–µ–Ω—å 14 (–æ—Å—Ç–∞–Ω–Ω—ñ–π –¥–µ–Ω—å –≤ –≤—ñ–∫–Ω—ñ)
                actual_prev_bpm.append(raw_bpm[i + DAYS_WINDOW - 1]) 
                # raw_bpm[i + DAYS_WINDOW] = —Ä–µ–∞–ª—å–Ω–∏–π –ø—É–ª—å—Å –Ω–∞ –¥–µ–Ω—å 15 (—Ü—ñ–ª—å–æ–≤–∏–π –¥–µ–Ω—å)
                actual_future_bpm.append(raw_bpm[i + DAYS_WINDOW])
            
            if len(X_test) == 0: 
                continue
            
            # –†–æ–±–∏–º–æ –ø–µ—Ä–µ–¥–∏–∫—Ü—ñ—ó
            X_test = np.array(X_test)
            pred_delta_z = model.predict(X_test, verbose=0)  # –ü–µ—Ä–µ–¥–∏–∫–æ–≤–∞–Ω–∞ –∑–º—ñ–Ω–∞ (–º–∞—Å—à—Ç–∞–±–æ–≤–∞–Ω–∞)
            pred_delta_bpm = sc_Y.inverse_transform(pred_delta_z).flatten()  # –ü–æ–≤–µ—Ä—Ç–∞—î–º–æ –¥–æ –æ—Ä–∏–≥—ñ–Ω–∞–ª—É
            
            # –ê–±—Å–æ–ª—é—Ç–Ω–∞ –ø–µ—Ä–µ–¥–∏–∫—Ü—ñ—è –ø—É–ª—å—Å—É = –ø—É–ª—å—Å —Å—å–æ–≥–æ–¥–Ω—ñ + –ø–µ—Ä–µ–¥–∏–∫–æ–≤–∞–Ω–∞ –∑–º—ñ–Ω–∞
            pred_final_bpm = np.array(actual_prev_bpm) + pred_delta_bpm
            y_real_bpm = np.array(actual_future_bpm)
            
            # –û–±—á–∏—Å–ª—é—î–º–æ –º–µ—Ç—Ä–∏–∫–∏ —Ç–æ—á–Ω–æ—Å—Ç—ñ
            mae_list.append(mean_absolute_error(y_real_bpm, pred_final_bpm))
            mse_list.append(mean_squared_error(y_real_bpm, pred_final_bpm))
            r2_list.append(r2_score(y_real_bpm, pred_final_bpm))
            
        return np.mean(mae_list), np.mean(mse_list), np.mean(r2_list)

    # –ó–∞–ø—É—Å–∫ 5-Fold CV –ø–∞—Ä–∞–ª–µ–ª—å–Ω–æ (–Ω–∞ –≤—Å—ñ—Ö —è–¥—Ä–∞—Ö –ø—Ä–æ—Ü–µ—Å–æ—Ä–∞)
    results = Parallel(n_jobs=5)(delayed(evaluate_delta_fold)(i, user_folds) for i in range(5))
    
    # –ó–±–∏—Ä–∞—î–º–æ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏ –∑ —É—Å—ñ—Ö —Ñ–æ–ª–¥—ñ–≤
    mae_final = [res[0] for res in results]
    mse_final = [res[1] for res in results]
    r2_final = [res[2] for res in results]
    
    # –í–∏–≤–æ–¥–∏–º–æ —É—Å–µ—Ä–µ–¥–Ω–µ–Ω—ñ —Ä–µ–∑—É–ª—å—Ç–∞—Ç–∏
    print("\n" + "="*40)
    print(f"–†–ï–ó–£–õ–¨–¢–ê–¢–ò DELTA-PREDICTION (Window={DAYS_WINDOW})")
    print("="*40)
    print(f"MAE: {np.mean(mae_final):.2f} BPM")  # –°–µ—Ä–µ–¥–Ω—è –∞–±—Å–æ–ª—é—Ç–Ω–∞ –ø–æ–º–∏–ª–∫–∞
    print(f"MSE: {np.mean(mse_final):.2f} BPM")  # –°–µ—Ä–µ–¥–Ω—è –∫–≤–∞–¥—Ä–∞—Ç–∏—á–Ω–∞ –ø–æ–º–∏–ª–∫–∞
    print(f"RMSE: {np.mean(np.sqrt(mse_final)):.2f} BPM")  # –ö–æ—Ä—ñ–Ω—å MSE
    print(f"R2:  {np.mean(r2_final):.4f}")  # –ö–æ–µ—Ñ—ñ—Ü—ñ—î–Ω—Ç –¥–µ—Ç–µ—Ä–º—ñ–Ω–∞—Ü—ñ—ó (0-1, —á–∏–º –≤–∏—â–µ —Ç–∏–º –∫—Ä–∞—â–µ)

    # ==========================================
    # 5. SHAP (Interpretability) & SAVE
    # ==========================================
    # SHAP –∞–Ω–∞–ª—ñ–∑—É—î –≤–∫–ª–∞–¥ –∫–æ–∂–Ω–æ—ó –æ–∑–Ω–∞–∫–∏ –≤ –ø–µ—Ä–µ–¥–∏–∫—Ü—ñ—é
    print("\nüîÑ –ü–µ—Ä–µ–Ω–∞–≤—á–∞–Ω–Ω—è —Ñ—ñ–Ω–∞–ª—å–Ω–æ—ó –º–æ–¥–µ–ª—ñ –¥–ª—è SHAP...")

    test_users_group = user_folds[-1]  # –û—Å—Ç–∞–Ω–Ω—è –≥—Ä—É–ø–∞ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
    train_users_group = np.concatenate(user_folds[:-1])  # –ü–µ—Ä—à—ñ 4 –≥—Ä—É–ø–∏ –¥–ª—è –Ω–∞–≤—á–∞–Ω–Ω—è

    # 1. TRAIN PREP - —è–∫ —Ä–∞–Ω—ñ—à–µ
    X_train_list, y_train_list = [], []
    for train_user in train_users_group:
        X_u, y_u_scaled, _, _, _ = process_user_with_delta(df, train_user, dynamic_cols, static_cols)
        
        X_wins, y_wins = [], []
        for i in range(len(X_u) - DAYS_WINDOW):
            X_wins.append(X_u[i : i + DAYS_WINDOW])
            y_wins.append(y_u_scaled[i + DAYS_WINDOW])
            
        if len(X_wins) > 0:
            X_train_list.append(np.array(X_wins))
            y_train_list.append(np.array(y_wins))

    X_train = np.concatenate(X_train_list, axis=0)
    y_train = np.concatenate(y_train_list, axis=0)

    # 2. TEST PREP - –æ–¥–∏–Ω –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á –¥–ª—è SHAP –∞–Ω–∞–ª—ñ–∑—É
    target_test_user = test_users_group[0]
    X_test_u, y_test_u, test_scaler_X, test_scaler_Y, _ = process_user_with_delta(df, target_test_user, dynamic_cols, static_cols)
    
    X_test_wins = []
    for i in range(len(X_test_u) - DAYS_WINDOW):
        X_test_wins.append(X_test_u[i : i + DAYS_WINDOW])
    X_test = np.array(X_test_wins)

    # 3. FINAL TRAIN - –Ω–∞–≤—á–∞—î–º–æ –Ω–æ–≤—É –º–æ–¥–µ–ª—å –Ω–∞ –≤—Å—ñ—Ö —Ç—Ä–µ–Ω—É–≤–∞–ª—å–Ω–∏—Ö –¥–∞–Ω–∏—Ö
    model = build_model((X_train.shape[1], X_train.shape[2]), model_type='GRU')
    model.fit(X_train, y_train, epochs=25, batch_size=32, verbose=0)

    # --- SHAP ANALYSIS ---
    print("–†–∞—Ö—É—î–º–æ SHAP values...")
    # –†–æ–∑–≥–æ—Ä—Ç–∞—î–º–æ 3D –¥–∞–Ω—ñ –≤ 2D –¥–ª—è SHAP
    X_train_flat = X_train.reshape(X_train.shape[0], -1)
    
    # –°–ø–∏—Å–æ–∫ –Ω–∞–∑–≤ —É—Å—ñ—Ö –æ–∑–Ω–∞–∫
    all_features = dynamic_cols + static_cols
    if 'is_weekend' in df.columns:
        all_features += ['is_weekend']

    # SHAP –≤–∏–∫–æ—Ä–∏—Å—Ç–æ–≤—É—î –ø—ñ–¥–º–Ω–æ–∂–∏–Ω—É –¥–∞–Ω–∏—Ö —è–∫ —Ñ–æ–Ω –¥–ª—è –ø–æ—Ä—ñ–≤–Ω—è–Ω–Ω—è (k-means —Å–ø—Ä–æ—â—É—î)
    background_summary = shap.kmeans(X_train_flat, 20) 

    def predict_wrapper(data_flat):
        """
        –û–±–≥–æ—Ä—Ç–∫–∞ –¥–ª—è –ø–µ—Ä–µ–¥–∞—á—ñ —Ä–æ–∑–≥–æ—Ä–Ω—É—Ç–∏—Ö –¥–∞–Ω–∏—Ö —É –º–æ–¥–µ–ª—å.
        SHAP –æ–∫–∞ –ø–µ—Ä–µ–¥–∞—î 2D –¥–∞–Ω—ñ, –∞ –º–æ–¥–µ–ª—å –æ—á—ñ–∫—É—î 3D (—á–∞—Å–æ–≤—ñ —Ä—è–¥–∏).
        """
        n_features = X_train.shape[2]
        # –†–æ–∑–≥–æ—Ä—Ç–∞—î–º–æ –Ω–∞–∑–∞–¥ –≤ 3D —Ñ–æ—Ä–º—É
        data_3d = data_flat.reshape(-1, DAYS_WINDOW, n_features)
        return model.predict(data_3d, verbose=0)

    # KernelExplainer –±—ñ–ª—å—à —É–Ω—ñ–≤–µ—Ä—Å–∞–ª—å–Ω–∏–π –∞–ª–µ –ø–æ–≤—ñ–ª—å–Ω—ñ—à–∏–π –∑–∞ DeepExplainer
    explainer = shap.KernelExplainer(predict_wrapper, background_summary)
    
    # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à—ñ 50 —Ç–µ—Å—Ç–æ–≤–∏—Ö –≤—ñ–∫–æ–Ω –¥–ª—è –∞–Ω–∞–ª—ñ–∑—É
    X_test_sample = X_test[:50]
    X_test_sample_flat = X_test_sample.reshape(50, -1)
    
    # –†–æ–∑—Ä–∞—Ö–æ–≤—É—î–º–æ SHAP values (–≤–∫–ª–∞–¥ –∫–æ–∂–Ω–æ—ó –æ–∑–Ω–∞–∫–∏)
    shap_values = explainer.shap_values(X_test_sample_flat)

    # –û–±—Ä–æ–±–∫–∞ SHAP output (–º–æ–∂–µ –±—É—Ç–∏ —Å–ø–∏—Å–æ–∫ –¥–ª—è –±–∞–≥–∞—Ç–æ–≤–∏—Ö–æ–¥—É)
    n_features = X_train.shape[2]
    if isinstance(shap_values, list):
        shap_vals = shap_values[0]  # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à–∏–π –≤–∏—Ö—ñ–¥
    else:
        shap_vals = shap_values

    # –†–æ–∑–≥–æ—Ä—Ç–∞—î–º–æ SHAP values –Ω–∞–∑–∞–¥ —É 3D (—á–∞—Å–æ–≤—ñ —Ä—è–¥–∏)
    shap_values_3d = shap_vals.reshape(-1, DAYS_WINDOW, n_features)
    # –£—Å–µ—Ä–µ–¥–Ω—è—î–º–æ –≤–∫–ª–∞–¥–∏ –ø–æ –¥–Ω—è—Ö (—Å—É–º—É—î–º–æ –≤–∫–ª–∞–¥ –∫–æ–∂–Ω–æ—ó –æ–∑–Ω–∞–∫–∏ –∑–∞ —É—Å—ñ–º–∞ –¥–Ω—è–º–∏)
    shap_values_combined = np.sum(shap_values_3d, axis=1) 

    # –£—Å–µ—Ä–µ–¥–Ω—è—î–º–æ –¥–∞–Ω—ñ –ø–æ –¥–Ω—è—Ö –¥–ª—è –≤—ñ–∑—É–∞–ª—ñ–∑–∞—Ü—ñ—ó
    X_test_sample_3d = X_test_sample.reshape(-1, DAYS_WINDOW, n_features)
    X_test_sample_combined = np.mean(X_test_sample_3d, axis=1)

    # –í—ñ–∑—É–∞–ª—ñ–∑—É—î–º–æ –≤–∞–∂–ª–∏–≤—ñ—Å—Ç—å –æ–∑–Ω–∞–∫
    plt.figure(figsize=(10, 6))
    shap.summary_plot(shap_values_combined, X_test_sample_combined, feature_names=all_features)
    
    # –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª—ñ —Ç–∞ —Å–∫–∞–ª–µ—Ä—ñ–≤ –¥–ª—è –ø–æ–¥–∞–ª—å—à–æ–≥–æ –≤–∏–∫–æ—Ä–∏—Å—Ç–∞–Ω–Ω—è
    print("\nüíæ –ó–±–µ—Ä–µ–∂–µ–Ω–Ω—è —Ñ–∞–π–ª—ñ–≤...")
    model.save(f'gru{DAYS_WINDOW}_delta_model.keras')  # –ó–±–µ—Ä–µ–∂–µ–Ω—è —è–∫ gru14_delta_model.keras
    joblib.dump(test_scaler_X, 'scaler_X.pkl')  # –î–ª—è –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –≤—Ö–æ–¥—É
    joblib.dump(test_scaler_Y, 'scaler_Y.pkl')  # –î–ª—è –∑–≤–æ—Ä–æ—Ç–Ω–æ–≥–æ –º–∞—Å—à—Ç–∞–±—É–≤–∞–Ω–Ω—è –≤–∏—Ö–æ–¥—É
    joblib.dump(all_features, 'model_features.pkl')  # –ù–∞–∑–≤–∏ –æ–∑–Ω–∞–∫ –¥–ª—è —Ç–µ—Å—Ç—É–≤–∞–Ω–Ω—è
    print("‚úÖ –í—Å–µ –∑–±–µ—Ä–µ–∂–µ–Ω–æ —É—Å–ø—ñ—à–Ω–æ!")