import os
import pandas as pd
import numpy as np
import joblib
import matplotlib.pyplot as plt
from keras.models import load_model
from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error

# ==========================================
# 1. –ù–ê–õ–ê–®–¢–£–í–ê–ù–ù–Ø
# ==========================================
DAYS_WINDOW = 3
dynamic_cols = [
    'steps', 'very_active_minutes', 'minutesAsleep', 'sleep_efficiency', 
    'nremhr', 'stress_score', 'nightly_temperature', 'resting_hr',
    'chronic_steps', 'acute_steps', 'acwr' 
]
static_cols = ['age', 'bmi']
weekend_col = ['is_weekend']
target_col = 'hr_delta'

BASE_PATH = 'cursova/models_ensemble/'
DATA_PATH = 'cursova/daily_fitbit_sema_df_processed.csv'

# ==========================================
# 2. –ü–Ü–î–ì–û–¢–û–í–ö–ê "–ß–ò–°–¢–ò–•" –î–ê–ù–ò–• (–ë–ï–ó –°–ö–ï–ô–õ–ò–ù–ì–£)
# ==========================================
def get_clean_user_df(df, user_id):
    """–ì–æ—Ç—É—î DataFrame –∑ —É—Å—ñ–º–∞ —Ñ—ñ—á–∞–º–∏, –∞–ª–µ –ë–ï–ó –Ω–æ—Ä–º–∞–ª—ñ–∑–∞—Ü—ñ—ó."""
    user_df = df[df['id'] == user_id].copy()
    
    # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤–∏—Ö—ñ–¥–Ω–∏—Ö
    if 'date' in user_df.columns:
        user_df['date'] = pd.to_datetime(user_df['date'])
        user_df['is_weekend'] = (user_df['date'].dt.dayofweek >= 5).astype(int)
    else:
        user_df['is_weekend'] = 0

    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü—ñ—è —Å—Ç–∞—Ç–∏–∫–∏
    user_df['age'] = pd.to_numeric(user_df['age'], errors='coerce').fillna(30)
    user_df['bmi'] = pd.to_numeric(user_df['bmi'], errors='coerce').fillna(25)
    
    # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –Ω–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è
    user_df['chronic_steps'] = user_df['steps'].rolling(window=28, min_periods=1).mean()
    user_df['acute_steps'] = user_df['steps'].rolling(window=7, min_periods=1).mean()
    user_df['acwr'] = user_df['acute_steps'] / (user_df['chronic_steps'] + 1)
    user_df['hr_delta'] = user_df['resting_hr'].diff().fillna(0)
    
    user_df = user_df.ffill().bfill()
    user_df = user_df.iloc[1:].reset_index(drop=True)
    return user_df

# ==========================================
# 3. –ó–ê–í–ê–ù–¢–ê–ñ–ï–ù–ù–Ø –ê–ù–°–ê–ú–ë–õ–Æ
# ==========================================
print("üîÑ –ó–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–Ω—è –º–æ–¥–µ–ª–µ–π —Ç–∞ —ó—Ö —ñ–Ω–¥–∏–≤—ñ–¥—É–∞–ª—å–Ω–∏—Ö —Å–∫–µ–π–ª–µ—Ä—ñ–≤...")
models_info = {}
for m_name in ['gru', 'lstm', 'cnn']:
    m_path = os.path.join(BASE_PATH, m_name)
    models_info[m_name] = {
        'model': load_model(os.path.join(m_path, f'{m_name}_model.keras')),
        'scaler_X': joblib.load(os.path.join(m_path, 'scaler_X.pkl')),
        'scaler_Y': joblib.load(os.path.join(m_path, 'scaler_Y.pkl'))
        # 'model': load_model(f'cursova/models&scaller&features&test/{m_name}3_delta_model.keras'),
        # 'scaler_X': joblib.load(f'cursova/models&scaller&features&test/scaler_X.pkl'),
        # 'scaler_Y': joblib.load(f'cursova/models&scaller&features&test/scaler_Y.pkl')
    }
print("‚úÖ –£—Å—ñ –º–æ–¥–µ–ª—ñ —Ç–∞ —Å–∫–µ–π–ª–µ—Ä–∏ –∑–∞–≤–∞–Ω—Ç–∞–∂–µ–Ω–æ.")

# ==========================================
# 4. –û–¶–Ü–ù–ö–ê
# ==========================================
def evaluate_on_users(user_ids, set_name, df):
    print(f"üìä –û–±—Ä–æ–±–∫–∞ –≤–∏–±—ñ—Ä–∫–∏: {set_name}...")
    all_results = []
    
    for u in user_ids:
        # 1. –û—Ç—Ä–∏–º—É—î–º–æ —á–∏—Å—Ç—ñ –¥–∞–Ω—ñ –∫–æ—Ä–∏—Å—Ç—É–≤–∞—á–∞
        user_df = get_clean_user_df(df, u)
        if len(user_df) <= DAYS_WINDOW: continue

        model_predictions_bpm = {}
        y_real_bpm = user_df['resting_hr'].values[DAYS_WINDOW:]

        # 2. –ü—Ä–æ–≥–Ω–æ–∑ –∫–æ–∂–Ω–æ—é –º–æ–¥–µ–ª–ª—é –∑—ñ —Å–≤–æ—ó–º —Å–∫–µ–π–ª–µ—Ä–æ–º
        for m_name, tools in models_info.items():
            # –°–∫–µ–π–ª–∏–Ω–≥ –≤—Ö–æ–¥—É —Å–∞–º–µ –¥–ª—è —Ü—ñ—î—ó –º–æ–¥–µ–ª—ñ
            dyn_scaled = tools['scaler_X'].transform(user_df[dynamic_cols].values)
            
            stat_data = user_df[static_cols].values.astype(float)
            stat_data[:, 0] /= 100.0
            stat_data[:, 1] /= 50.0
            week_data = user_df[['is_weekend']].values
            
            X_final_user = np.hstack((dyn_scaled, stat_data, week_data))

            # –°—Ç–≤–æ—Ä–µ–Ω–Ω—è –≤—ñ–∫–æ–Ω
            X_wins = []
            for i in range(len(X_final_user) - DAYS_WINDOW):
                X_wins.append(X_final_user[i : i + DAYS_WINDOW])
            X_wins = np.array(X_wins)

            # –ü—Ä–æ–≥–Ω–æ–∑ —Ç–∞ –∑–≤–æ—Ä–æ—Ç–Ω–∏–π —Å–∫–µ–π–ª–∏–Ω–≥
            p_z = tools['model'].predict(X_wins, verbose=0)
            p_delta = tools['scaler_Y'].inverse_transform(p_z).flatten()
            
            # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ BPM (–ü—É–ª—å—Å_–≤—á–æ—Ä–∞ + –î–µ–ª—å—Ç–∞_—Å—å–æ–≥–æ–¥–Ω—ñ)
            prev_bpm = user_df['resting_hr'].values[DAYS_WINDOW-1 : -1]
            model_predictions_bpm[m_name] = prev_bpm + p_delta

        # 3. –ê–Ω—Å–∞–º–±–ª—ñ
        ens_weighted = (model_predictions_bpm['gru'] * 0.33 + 
                        model_predictions_bpm['lstm'] * 0.33 + 
                        model_predictions_bpm['cnn'] * 0.34)
        
        preds_to_eval = {
            'GRU': model_predictions_bpm['gru'],
            'LSTM': model_predictions_bpm['lstm'],
            'CNN': model_predictions_bpm['cnn'],
            'Ens_Weighted': ens_weighted,
        }

        for name, pred in preds_to_eval.items():
            all_results.append({
                "Model": name, 
                "Set": set_name, 
                "MAE": mean_absolute_error(y_real_bpm, pred),
                "RMSE": np.sqrt(mean_squared_error(y_real_bpm, pred)),
                "R2": r2_score(y_real_bpm, pred)
            })

    return pd.DataFrame(all_results)

def evaluate_on_users_global(user_ids, set_name, df):
    print(f"üìä –ì–ª–æ–±–∞–ª—å–Ω–∏–π —Ä–æ–∑—Ä–∞—Ö—É–Ω–æ–∫: {set_name}...")
    
    # –°–ª–æ–≤–Ω–∏–∫–∏ –¥–ª—è –Ω–∞–∫–æ–ø–∏—á–µ–Ω–Ω—è –≤—Å—ñ—Ö –ø—Ä–æ–≥–Ω–æ–∑—ñ–≤ —Ç–∞ —Ä–µ–∞–ª—å–Ω–∏—Ö –∑–Ω–∞—á–µ–Ω—å
    all_preds = {m: [] for m in ['gru', 'lstm', 'cnn', 'ens_2']}
    all_actuals = []

    for u in user_ids:
        user_df = get_clean_user_df(df, u)
        if len(user_df) <= DAYS_WINDOW: continue

        model_predictions_bpm = {}
        y_real_bpm = user_df['resting_hr'].values[DAYS_WINDOW:]

        for m_name, tools in models_info.items():
            # –°–∫–µ–π–ª–∏–Ω–≥ —Ç–∞ –ø—ñ–¥–≥–æ—Ç–æ–≤–∫–∞ X_wins (—è–∫ —É –≤–∞—à–æ–º—É –∫–æ–¥—ñ)
            dyn_scaled = tools['scaler_X'].transform(user_df[dynamic_cols].values)
            stat_data = user_df[static_cols].values.astype(float)
            stat_data[:, 0] /= 100.0
            stat_data[:, 1] /= 50.0
            X_final_user = np.hstack((dyn_scaled, stat_data, user_df[['is_weekend']].values))

            X_wins = np.array([X_final_user[i : i + DAYS_WINDOW] for i in range(len(X_final_user) - DAYS_WINDOW)])

            # –ü—Ä–æ–≥–Ω–æ–∑
            p_z = tools['model'].predict(X_wins, verbose=0)
            p_delta = tools['scaler_Y'].inverse_transform(p_z).flatten()
            
            prev_bpm = user_df['resting_hr'].values[DAYS_WINDOW-1 : -1]
            model_predictions_bpm[m_name] = prev_bpm + p_delta
            
            # –ù–∞–∫–æ–ø–∏—á—É—î–º–æ
            all_preds[m_name].extend(model_predictions_bpm[m_name])

        # –ê–Ω—Å–∞–º–±–ª—å GRU+LSTM
        ens_2 = (model_predictions_bpm['gru'] + model_predictions_bpm['lstm']) / 2
        all_preds['ens_2'].extend(ens_2)
        all_actuals.extend(y_real_bpm)

    # –†–æ–∑—Ä–∞—Ö—É–Ω–æ–∫ –º–µ—Ç—Ä–∏–∫ –ø–æ –≤—Å—å–æ–º—É –Ω–∞–∫–æ–ø–∏—á–µ–Ω–æ–º—É –º–∞—Å–∏–≤—É
    results = []
    y_true = np.array(all_actuals)
    for name in all_preds:
        y_p = np.array(all_preds[name])
        results.append({
            "Model": name.upper(),
            "Set": set_name,
            "MAE": mean_absolute_error(y_true, y_p),
            "R2": r2_score(y_true, y_p)
        })
    return pd.DataFrame(results)

if __name__ == "__main__":
    df_full = pd.read_csv(DATA_PATH)
    all_users = df_full['id'].unique()
    train_users = all_users[:int(len(all_users)*0.8)]
    test_users = all_users[int(len(all_users)*0.8):]

    train_results = evaluate_on_users(train_users, "Train", df_full)
    test_results = evaluate_on_users(test_users, "Test", df_full)

    final_report = pd.concat([train_results, test_results]).groupby(['Model', 'Set']).mean().reset_index()
    print("\n" + "="*60)
    print("–ó–í–Ü–¢ –¢–û–ß–ù–û–°–¢–Ü –ú–û–î–ï–õ–ï–ô")
    print("="*60)
    print(final_report.sort_values(by=['Model', 'Set']).to_string(index=False))